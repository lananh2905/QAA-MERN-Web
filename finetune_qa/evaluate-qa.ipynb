{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate TEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T19:19:20.917894Z",
     "iopub.status.busy": "2025-06-01T19:19:20.917627Z",
     "iopub.status.idle": "2025-06-01T19:19:29.839249Z",
     "shell.execute_reply": "2025-06-01T19:19:29.838644Z",
     "shell.execute_reply.started": "2025-06-01T19:19:20.917869Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 19:19:26.227454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748805566.251071     569 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748805566.258410     569 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import os\n",
    "import evaluate\n",
    "from transformers import pipeline\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T19:19:29.840494Z",
     "iopub.status.busy": "2025-06-01T19:19:29.840013Z",
     "iopub.status.idle": "2025-06-01T19:19:29.975970Z",
     "shell.execute_reply": "2025-06-01T19:19:29.975381Z",
     "shell.execute_reply.started": "2025-06-01T19:19:29.840474Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(os.getenv(\"HF_TOKEN\"))  # D√°n token b·∫°n v·ª´a copy v√†o ƒë√¢y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T19:19:29.977546Z",
     "iopub.status.busy": "2025-06-01T19:19:29.977271Z",
     "iopub.status.idle": "2025-06-01T19:19:31.324585Z",
     "shell.execute_reply": "2025-06-01T19:19:31.323750Z",
     "shell.execute_reply.started": "2025-06-01T19:19:29.977508Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'uit_id', 'title', 'context', 'question', 'answers', 'is_impossible', 'plausible_answers'],\n",
       "        num_rows: 28454\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'uit_id', 'title', 'context', 'question', 'answers', 'is_impossible', 'plausible_answers'],\n",
       "        num_rows: 3814\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'uit_id', 'title', 'context', 'question', 'answers', 'is_impossible', 'plausible_answers'],\n",
       "        num_rows: 7301\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"taidng/UIT-ViQuAD2.0\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T19:19:31.325605Z",
     "iopub.status.busy": "2025-06-01T19:19:31.325378Z",
     "iopub.status.idle": "2025-06-01T19:19:31.339261Z",
     "shell.execute_reply": "2025-06-01T19:19:31.338312Z",
     "shell.execute_reply.started": "2025-06-01T19:19:31.325586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 25609\n",
      "Validation size: 3814\n",
      "Test size: 2845\n"
     ]
    }
   ],
   "source": [
    "# T·ªïng s·ªë ph·∫ßn t·ª≠ trong t·∫≠p train g·ªëc\n",
    "total_len = len(dataset[\"train\"])\n",
    "test_size = total_len // 10  # L·∫•y 1/10\n",
    "\n",
    "# Chia t·∫≠p train: 9/10 ƒë·∫ßu gi·ªØ l√†m train, 1/10 cu·ªëi l√†m test\n",
    "train_dataset = dataset[\"train\"].select(range(0, total_len - test_size))\n",
    "test_dataset = dataset[\"train\"].select(range(total_len - test_size, total_len))\n",
    "val_dataset = dataset[\"validation\"]\n",
    "\n",
    "# Ki·ªÉm tra k·∫øt qu·∫£\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Validation size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T19:19:31.340538Z",
     "iopub.status.busy": "2025-06-01T19:19:31.340224Z",
     "iopub.status.idle": "2025-06-01T19:19:31.353583Z",
     "shell.execute_reply": "2025-06-01T19:19:31.352880Z",
     "shell.execute_reply.started": "2025-06-01T19:19:31.340510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_features(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=384,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = tokenized[\"offset_mapping\"]\n",
    "    example_ids = []\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized[\"input_ids\"][i]\n",
    "        sample_idx = sample_mapping[i]\n",
    "        answer = examples[\"answers\"][sample_idx]\n",
    "        is_impossible = examples[\"is_impossible\"][sample_idx]\n",
    "\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        if is_impossible or len(answer[\"text\"]) == 0:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "            tokenized[\"offset_mapping\"][i] = [(0, 0)] * len(offsets)  # ƒê√°nh d·∫•u l√† kh√¥ng h·ª£p l·ªá\n",
    "        else:\n",
    "            start_char = answer[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answer[\"text\"][0])\n",
    "            sequence_ids = tokenized.sequence_ids(i)\n",
    "\n",
    "            context_start = sequence_ids.index(1)\n",
    "            context_end = len(sequence_ids) - 1 - list(reversed(sequence_ids)).index(1)\n",
    "\n",
    "            if offsets[context_start][0] > start_char or offsets[context_end][1] < end_char:\n",
    "                start_positions.append(0)\n",
    "                end_positions.append(0)\n",
    "                tokenized[\"offset_mapping\"][i] = [(0, 0)] * len(offsets)\n",
    "            else:\n",
    "                idx = context_start\n",
    "                while idx <= context_end and offsets[idx][0] <= start_char:\n",
    "                    idx += 1\n",
    "                start_positions.append(idx - 1)\n",
    "\n",
    "                idx = context_end\n",
    "                while idx >= context_start and offsets[idx][1] >= end_char:\n",
    "                    idx -= 1\n",
    "                end_positions.append(idx + 1)\n",
    "\n",
    "    tokenized[\"start_positions\"] = start_positions\n",
    "    tokenized[\"end_positions\"] = end_positions\n",
    "    tokenized[\"example_id\"] = example_ids\n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T19:20:03.820792Z",
     "iopub.status.busy": "2025-06-01T19:20:03.819975Z",
     "iopub.status.idle": "2025-06-01T19:20:04.227943Z",
     "shell.execute_reply": "2025-06-01T19:20:04.227184Z",
     "shell.execute_reply.started": "2025-06-01T19:20:03.820764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load metric\n",
    "squad_metric = evaluate.load(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T19:20:04.229316Z",
     "iopub.status.busy": "2025-06-01T19:20:04.229082Z",
     "iopub.status.idle": "2025-06-01T19:20:04.237402Z",
     "shell.execute_reply": "2025-06-01T19:20:04.236524Z",
     "shell.execute_reply.started": "2025-06-01T19:20:04.229298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size=20, max_answer_length=30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    example_id_to_index = {k[\"id\"]: i for i, k in enumerate(examples)}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[feature[\"example_id\"]].append(i)\n",
    "\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    for example in examples:\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        feature_indices = features_per_example[example_id]\n",
    "\n",
    "        best_score = -float(\"inf\")\n",
    "        best_answer = \"\"\n",
    "\n",
    "        for i in feature_indices:\n",
    "            start_logits = all_start_logits[i]\n",
    "            end_logits = all_end_logits[i]\n",
    "            offset_mapping = features[i][\"offset_mapping\"]\n",
    "\n",
    "            for start_index in np.argsort(start_logits)[-n_best_size:]:\n",
    "                for end_index in np.argsort(end_logits)[-n_best_size:]:\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                        or end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    score = start_logits[start_index] + end_logits[end_index]\n",
    "\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_answer = context[start_char:end_char]\n",
    "\n",
    "        if example.get(\"is_impossible\", False) or best_answer.strip() == \"\":\n",
    "            predictions[example_id] = \"\"\n",
    "        else:\n",
    "            predictions[example_id] = best_answer.strip()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T19:20:04.238693Z",
     "iopub.status.busy": "2025-06-01T19:20:04.238141Z",
     "iopub.status.idle": "2025-06-01T19:20:04.252813Z",
     "shell.execute_reply": "2025-06-01T19:20:04.252168Z",
     "shell.execute_reply.started": "2025-06-01T19:20:04.238646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions = postprocess_qa_predictions(\n",
    "        test_dataset,\n",
    "        tokenized_test,\n",
    "        p.predictions\n",
    "    )\n",
    "\n",
    "    formatted_predictions = [\n",
    "        {\n",
    "            \"id\": k,\n",
    "            \"prediction_text\": v,\n",
    "            \"no_answer_probability\": 0.0\n",
    "        }\n",
    "        for k, v in predictions.items()\n",
    "    ]\n",
    "\n",
    "    references = [\n",
    "        {\n",
    "            \"id\": ex[\"id\"],\n",
    "            \"answers\": ex[\"answers\"]\n",
    "            if ex[\"answers\"][\"text\"]\n",
    "            else {\"text\": [\"\"], \"answer_start\": [0]}\n",
    "        }\n",
    "        for ex in test_dataset\n",
    "    ]\n",
    "\n",
    "    return squad_metric.compute(predictions=formatted_predictions, references=references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T19:20:07.444018Z",
     "iopub.status.busy": "2025-06-01T19:20:07.443484Z",
     "iopub.status.idle": "2025-06-01T19:20:07.447509Z",
     "shell.execute_reply": "2025-06-01T19:20:07.446723Z",
     "shell.execute_reply.started": "2025-06-01T19:20:07.443991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_ids = {\n",
    "    \"mBERT_QA\": \"DatTran0509/Finetune_mBERT_QA\",\n",
    "    \"XLMR_RoBerta_Base\": \"DatTran0509/Finetune_XLM_R_base_QA_NEW\",  # v√≠ d·ª•: \"vinai/phobert-base-qa\"\n",
    "    \"XLMR_RoBerta_Large\": \"DatTran0509/Finetune_XLM_R_large_QA_New\"   # v√≠ d·ª•: \"csarron/roberta-base-squad-v1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T19:25:12.204360Z",
     "iopub.status.busy": "2025-06-01T19:25:12.204063Z",
     "iopub.status.idle": "2025-06-01T19:29:44.749163Z",
     "shell.execute_reply": "2025-06-01T19:29:44.748250Z",
     "shell.execute_reply.started": "2025-06-01T19:25:12.204338Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating model: mBERT_QA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ mBERT_QA ‚Äî EM: 56.03% | F1: 69.58%\n",
      "--------------------------------------------------\n",
      "üîç Evaluating model: XLMR_RoBerta_Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ XLMR_RoBerta_Base ‚Äî EM: 57.96% | F1: 71.69%\n",
      "--------------------------------------------------\n",
      "üîç Evaluating model: XLMR_RoBerta_Large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 02:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ XLMR_RoBerta_Large ‚Äî EM: 63.73% | F1: 79.86%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# L∆∞u k·∫øt qu·∫£\n",
    "results = {}\n",
    "\n",
    "# ƒê√°nh gi√° t·ª´ng model\n",
    "for name, model_id in model_ids.items():\n",
    "    print(f\"üîç Evaluating model: {name}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_id)\n",
    "\n",
    "    # Tokenize v·ªõi tokenizer ri√™ng\n",
    "    tokenized_test = test_dataset.map(prepare_features, batched=True, remove_columns=test_dataset.column_names)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results/{name.replace('/', '_')}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        per_device_eval_batch_size=32,\n",
    "        logging_dir=f\"./logs/{name.replace('/', '_')}\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        eval_dataset=tokenized_test,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    eval_result = trainer.evaluate()\n",
    "    results[name] = {\n",
    "        \"EM\": eval_result.get(\"eval_exact\", 0),\n",
    "        \"F1\": eval_result.get(\"eval_f1\", 0)\n",
    "    }\n",
    "\n",
    "    print(f\"‚úÖ {name} ‚Äî EM: {results[name]['EM']:.2f}% | F1: {results[name]['F1']:.2f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
